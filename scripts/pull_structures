#!/usr/bin/env python
"""
Retreive protein structures (PDB files) representing the center of
each of the states in a hidden Markov model
"""
import os
import glob
import json
import numpy as np
import mdtraj as md
import matplotlib.pyplot as pp
from mixtape.utils import iterobjects, load_timeseries
from sklearn.mixture import log_multivariate_normal_density
from argparse import ArgumentParser

parser = ArgumentParser(description=__doc__)
parser.add_argument('--filename', required=True, help='Path to the jsonlines output file containg the HMMs, written by md_ghmm')
parser.add_argument('--n-states', type=int, required=True, help='Number of states in the model to select from')
parser.add_argument('--n-per-state', type=int, default=3, help='Number of structures to pull from each state')
parser.add_argument('--lag-time', type=int, required=True, help='Training lag time of the model to select from')
parser.add_argument('--topology', required=True, help='Topology file for the system')

group_munge = parser.add_argument_group('Munging Options')
group_vector = group_munge.add_mutually_exclusive_group(required=True)
group_vector.add_argument('-d', '--distance-pairs', type=str,
                         help='''Vectorize the MD trajectories by extracting timeseries of the distance
                         between pairs of atoms in each frame. Supply a text file where each row contains
                         the space-separate indices of two atoms which form a pair to monitor''')
group_vector.add_argument('-a', '--atom-indices', type=str, help='''Superpose each MD conformation on the
                        coordinates in the topology file, and then use the distance from each atom in
                        the reference conformation to the corresponding atom in each MD conformation.''')
parser.add_argument('--dir', help='Directory containing the trajectory files')
parser.add_argument('--ext', help='File extension of the trajectory files')


def main():
    args = parser.parse_args()
    matches = [o for o in iterobjects(args.filename) if o['n_states'] == args.n_states and o['train_lag_time'] == args.lag_time]
    if len(matches) == 0:
        parser.error('No model with n_states=%d, train_lag_time=%d in %s.' % (args.n_states, args.lag_time, args.filename))
    obj = matches[0]

    means = np.array(obj['means'])
    vars = np.array(obj['vars'])
    transmat = np.array(obj['transmat'])

    topology = md.load(args.topology)
    atom_indices = np.loadtxt(args.atom_indices, dtype=int)
    filenames = glob.glob(os.path.join(args.dir, '*.%s' % args.ext))
    xx, ii, ff = load_timeseries(filenames, atom_indices, topology)

    logprob = log_multivariate_normal_density(xx, means, vars, covariance_type='diag')
    assignments = np.argmax(logprob, axis=1)
    probs = np.max(logprob, axis=1)

    for state in range(means.shape[0]):
        # pick the structures that have the highest log
        # probability in this state
        p = probs[assignments==state]
        sorted_filenms = ff[assignments==state][p.argsort()]
        sorted_indices = ii[assignments==state][p.argsort()]

        selected_indices = sorted_indices[-args.n_per_state:][::-1]
        selected_filenms = sorted_filenms[-args.n_per_state:][::-1]

        framelist = [md.load_frame(fn, i) for i, fn in zip(selected_indices, selected_filenms)]

        t = reduce(lambda a, b: a.join(b), framelist)
        t.superpose(t)
        outfn = 'structures-%s.pdb' % state
        print 'saving %s' % outfn
        t.save(outfn)


if __name__ == '__main__':
    main()
