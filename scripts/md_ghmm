#!/usr/bin/env python
"""
Fit a (collection of) gaussian fusion hidden Markov models to
distance pairs in molecular dynamics trajectories.
"""
import os
import sys
import glob
import json
import time
import argparse
from pprint import pprint
import numpy as np
import mdtraj as md

from sklearn.cross_validation import KFold
from mixtape.ghmm import GaussianFusionHMM
from mixtape.lagtime import contraction

################################################################################
# Setup parser
################################################################################

parser = argparse.ArgumentParser(description=__doc__)
group_mdtraj = parser.add_argument_group('MDTraj Options')
group_mdtraj.add_argument('--dir', type=str, help='''Directory containing
                    the trajectories to load''', required=True)
group_mdtraj.add_argument('--top', type=str, help='''Topology file for loading
                   trajectores''')
group_mdtraj.add_argument('--ext', help='File extension of the trajectories',
                    required=True,
                    choices=[e[1:] for e in md.trajectory._FormatRegistry.loaders.keys()])

group_munge = parser.add_argument_group('Munging Options')
group_vector = group_munge.add_mutually_exclusive_group(required=True)
group_vector.add_argument('-d', '--distance-pairs', type=str,
                         help='''Vectorize the MD trajectories by extracting timeseries of the distance
                         between pairs of atoms in each frame. Supply a text file where each row contains
                         the space-separate indices of two atoms which form a pair to monitor''')
group_vector.add_argument('-a', '--atom-indices', type=str, help='''Superpose each MD conformation on the
                        coordinates in the topology file, and then use the distance from each atom in
                        the reference conformation to the corresponding atom in each MD conformation.''')
group_munge.add_argument('-sp', '--split', type=int, help='''Split trajectories into smaller chunks. This
                         looses some counts (i.e. like 1%% of the counts are lost with --split 100), but can
                         help with speed (on gpu + multicore cpu) and numerical instabilities that come when
                         trajectories get extremely long.''', default=10000)

group_hmm = parser.add_argument_group('HMM Options')
group_hmm.add_argument('-k', '--n-states', type=int, default=[2], nargs='+',
                    help='Number of states in the models. Default = [2,]')
group_hmm.add_argument('-l', '--lag-times', type=int, default=[1], nargs='+',
                    help='Lag time(s) of the model(s). Default = [1,]')
group_hmm.add_argument('--platform', choices=['cuda', 'cpu', 'sklearn'],
                    default='cpu', help='Implementation platform. default="cpu"')
group_hmm.add_argument('--fusion-prior', type=float, default=1e-2, help='''Strength of
                    the adaptive fusion prior. default=1e-2''')
group_hmm.add_argument('--n-em-iter', type=int, default=100, help='''Maximum number of
                    iterations of EM. default=100''')
group_hmm.add_argument('--thresh', type=float, default=1e-2, help='''Convergence
                    criterion for EM. Quit when the log likelihood decreases by
                    less than this threshold. default=1e-2''')
group_hmm.add_argument('--n-lqa-iter', type=int, default=10, help='''Max number of
                    iterations for local quadradric approximation solving the
                    fusion-L1. default=10''')
group_hmm.add_argument('--reversible-type', choices=['mle', 'transpose'], default='mle',
                    help='''Method by which the model is constrained to be
                    reversible. default="mle"''')

group_cv = parser.add_argument_group('Cross Validation')
group_cv.add_argument('--n-cv', type=int, default=1, help='''Run N-fold cross
                    validation. default=2''')
group_cv.add_argument('--test-lag-time', type=int, default=1,
                    help='Lag time at which to test the models. default=1')

group_out = parser.add_argument_group('Output')
group_out.add_argument('-o', '--out', help='Output file. default="hmms.jsonlines"', default='hmms.jsonlines')


def fit(train, test, n_states, n_features, train_lag_time, fold, args, outfile):
    pprint(args.__dict__)
    kwargs = dict(n_states=n_states, n_features=n_features, n_em_iter=args.n_em_iter,
        n_lqa_iter = args.n_lqa_iter, fusion_prior=args.fusion_prior,
        thresh=args.thresh, reversible_type=args.reversible_type,
                platform=args.platform)
    model = GaussianFusionHMM(**kwargs)

    start = time.time()
    model.fit(train)
    end = time.time()

    result = {
        'timescales': (model.timescales_() * train_lag_time).tolist(),
        'transmat': model.transmat_.tolist(),
        'populations': model.populations_.tolist(),
        'n_states': model.n_states,
        'split': args.split,
        'fusion_prior': args.fusion_prior,
        'train_lag_time': train_lag_time,
        'train_time': end - start,
        'means': model.means_.tolist(),
        'vars': model.vars_.tolist(),
        'train_logprob': model.fit_logprob_[-1],
        'n_train_observations': sum(len(t) for t in train),
        'n_test_observations': sum(len(t) for t in test),
        'test_lag_time': args.test_lag_time,
        'cross_validation_fold': fold,
        'cross_validation_nfolds': args.n_cv,
    }

    # Reformulate the model to be at the test_lag_time by contracting
    # the transition matrix
    try:
        model.transmat_ = contraction(model.transmat_, float(train_lag_time) / float(args.test_lag_time))
        result['test_logprob'] = model.score(test)
    except:
        result['test_logprob'] = float('nan')

    if not np.all(np.isfinite(model.transmat_)):
        print 'Nonfinite numbers in transmat !!'

    json.dump(result, outfile)
    outfile.write('\n')


def main():
    args = parser.parse_args()
    top = md.load(args.top) if args.top is not None else None
    data = []

    if args.distance_pairs is not None:
        indices = np.loadtxt(args.distance_pairs, dtype=int, ndmin=2)
        if indices.shape[1] != 2:
            parser.error('distance-pairs must have shape (N, 2). %s had shape %s' % (args.distance_pairs, indices.shape))
    else:
        indices = np.loadtxt(args.atom_indices, dtype=int, ndmin=2)
        if indices.shape[1] != 1:
            parser.error('atom-indices must have shape (N, 1). %s had shape %s' % (args.atom_indices, indices.shape))
        indices = indices.reshape(-1)

    filenames = glob.glob(args.dir + '/*.' + args.ext)
    n_features = indices.shape[0]
    load_time_start = time.time()
    for tfn in filenames:
        kwargs = {} if tfn.endswith('h5') else {'top': top}
        for t in md.iterload(tfn, chunk=args.split, **kwargs):
            if args.distance_pairs is not None:
                item = md.geometry.compute_distances(t, indices, periodic=False)
            else:
                if top is None:
                    parser.error('--top is required')
                t.superpose(top, atom_indices=indices)
                diff2 = (t.xyz[:, indices] - top.xyz[0, indices])**2
                item = np.sqrt(np.sum(diff2, axis=2))
                data.append(item)

    print 'Loading data into memory + vectorization: %f s' % (time.time() - load_time_start)
    print 'Fitting with %s timeseries from %d trajectories with %d total observations' % (
        len(data), len(filenames), sum(len(e) for e in data))

    with open(args.out, 'a') as outfile:
        outfile.write('# %s\n' % ' '.join(sys.argv))

        for lag_time in args.lag_times:
            subsampled = [d[::lag_time] for d in data]
            for n_states in args.n_states:

                if args.n_cv > 1:
                    for fold, (train_i, test_i) in enumerate(KFold(n=len(data), n_folds=args.n_cv)):
                        train = [subsampled[i] for i in train_i]
                        test = [subsampled[i] for i in test_i]

                        fit(train, test, n_states, n_features, lag_time, fold, args, outfile)
                else:
                    fit(subsampled, subsampled, n_states, n_features, lag_time, 0, args, outfile)


if __name__ == '__main__':
    main()
